{
  "info": {
    "version": "1",
    "author": "borisef",
    "date": "18-02-2020",
    "update":"21-06-2020"

  },
  "run_params" : {
    "logfile_path" : "log/file.log",
    "log_verbosity" : "9",
    "log_stderr_verbosity" : "0",
    "prePath": "/media/borisef/nvmeSSD/projects/cppFlowATR/",
    "os": "LINUX_JETSON",
    "nms": "1",
    "nms_abs_thresh": "75",
    "nms_IoU_thresh": "0.1",
    "nms_IoU_thresh_VEHICLE2VEHICLE_SAME_SUB": "0.2",
    "nms_IoU_thresh_VEHICLE2VEHICLE": "0.3",
    "nms_IoU_thresh_VEHICLE2HUMAN": "0.6",
    "nms_IoU_thresh_HUMAN2HUMAN": "0.4", 
    "size_filter": "0",
    "size_matching_ranges": "{\"PERSON\":[0.15, 4.0], \"CAR\": [1.5, 7], \"LARGE_CAR\" : [5, 17], \"AMBIGUOUS\" : [2, 17]}",
    "lower_score_threshold": "0.5",
    "do_per_class_score_threshold": "0",
    "per_class_score_threshold": "{\"PERSON\":0.7, \"PRIVATE\": 0.9, \"COMMERCIAL\" : 0.8, \"PICKUP\" : 0.75, \"TRUCK\" : 0.8, \"BUS\" : 0.6, \"VAN\" : 0.7, \"TRACKTOR\" : 0.6 }", 
    "do_remove_edge_targets": "1",
    "edge_in_pixels": "50", 
    "do_CCM": "1",
    "CCM": "[1.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 1.0]",
    "CCMB": "[14.0, 7.0, -20.0]", 
    "crop_ATR": "0.15"
  
  },
  "models": [
    {
      "id": "0",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/frozen_inference_graph_all_MB3.pb",
      "nickname": "default_ATR",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "ALL",
      "width": "0",
      "height": "0",
      "imresize_factor": "1",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "ALL",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "1",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path_": "graphs/shalev/MB3_frozen_inference_graph_cars_5cm_1_2.pb",
      "load_path": "graphs/cars_exam2_MB3_14_07_20_5cm_wide_range_512_hpc/frozen_1_2M/frozen_inference_graph.pb",
      "nickname": "default_ATR_cars",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "CARS",
      "width": "0",
      "height": "0",
      "imresize_factor": "0.9",
      "max_batch_size": "64",
      "image_format": "RGB",
      "resolution": "5",
      "range": "ALL",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "2",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/frozen_inference_graph_all_MB3.pb",
      "nickname": "default_ATR_humans",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "HUMANS",
      "width": "0",
      "height": "0",
      "imresize_factor": "1.00",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "ALL",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "3",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/frozen_inference_graph_all_MB3.pb",
      "nickname": "default_ATR_near",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "ALL",
      "width": "0",
      "height": "0",
      "imresize_factor": "1.00",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "NEAR",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "4",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/shalev/MB3_frozen_inference_graph_cars_5cm_1_2.pb",
      "nickname": "default_ATR_cars_near",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "CARS",
      "width": "0",
      "height": "0",
      "imresize_factor": "1.00",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "NEAR",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "5",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/frozen_inference_graph_all_MB3.pb",
      "nickname": "default_ATR_humans_near",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "HUMANS",
      "width": "0",
      "height": "0",
      "imresize_factor": "0.8",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "NEAR",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "6",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/frozen_inference_graph_all_MB3.pb",
      "nickname": "default_ATR_far",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "ALL",
      "width": "0",
      "height": "0",
      "imresize_factor": "0.9",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "FAR",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "7",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/shalev/MB3_frozen_inference_graph_cars_5cm_1_2.pb",
      "nickname": "default_ATR_cars_far",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "CARS",
      "width": "0",
      "height": "0",
      "imresize_factor": "0.9",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "FAR",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "8",
      "task": "ATR",
      "filetype": ".pb",
      "mission": "0",
      "load_path": "graphs/frozen_inference_graph_all_MB3.pb",
      "nickname": "default_ATR_humans_far",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "HUMANS",
      "width": "0",
      "height": "0",
      "imresize_factor": "1.00",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "range": "FAR",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "20",
      "task": "CM",
      "filetype": ".pb",
      "mission": "0",
      "load_path_": "graphs/cm/output_graph_mnist_18_06_20.pb",
      "load_path_": "graphs/cm/cm.inout_fp32hwc.18_06_20.fp16.engine",
      "load_path": "graphs/cm/output_graph_try22.pb",
      "nickname": "default_CM",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "ALL",
      "width": "128",
      "height": "128",
       "margin": "0.2",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "input_layer":"conv2d_input_1",
      "output_layer":"dense_1_1/Softmax",
      "ckpt": "nullptr",
      "additional": "-nms 0 -opp 3"
    },
    {
      "id": "30",
      "task": "ATR-tiles",
      "filetype": ".pb",
      "mission": "0",
      "_load_path": "graphs/shalev/MB3_frozen_inference_graph_cars_5cm_1_2.pb",
      "load_path": "graphs/cars_exam2_MB3_14_07_20_5cm_wide_range_512_hpc/frozen_1_2M/frozen_inference_graph.pb",
      "nickname": "tiles",
      "max_objects": "300",
      "accuracy": "5",
      "speed": "5",
      "targets": "ALL",
      "width": "4000",
      "height": "2000",
      "imresize_factor": "-1",
      "max_batch_size": "1",
      "image_format": "RGB",
      "resolution": "5",
      "additional": "-nms 0 -opp 3"
    }
  ]
}
